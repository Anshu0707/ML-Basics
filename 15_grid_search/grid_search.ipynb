{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2516ce",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple; font-weight:bold\">GridSearch Cross Validation</span>      \n",
    "\n",
    "GridSearchCV is a technique used for HyperParameters tuning.                \n",
    "\n",
    "## <span style=\"color:blue; font-wieght:bold\">Hyper Parameter</span> \n",
    "\n",
    "- A hyperparameter is an external configuration variable set before the training process begins that controls how the model learns.                   \n",
    "- The \"hyper\" prefix indicates that it's a \"top-level\" variable that governs the learning process itself, unlike model parameters (like weights and biases) which are internal variables learned from the data during training.                 \n",
    "\n",
    "![alt text](assets/images/HyperParameters_Types.png)\n",
    "\n",
    "![alt text](assets/images/Hyper_Parameter_Tuning.png)                           \n",
    "\n",
    "         \n",
    "\n",
    "---         \n",
    "## There are three popular tehcniques used for finding optimal values of hyper parameters.                     \n",
    "\n",
    "\n",
    "### <span style=\"color:blue; font-wieght:bold\">1. GridSearch Cross Validation                              \n",
    "### <span style=\"color:blue; font-wieght:bold\">2. RandomizedSearch Cross Validation                             \n",
    "### <span style=\"color:blue; font-wieght:bold\">3. Bayesian Optimization                                 \n",
    "\n",
    "![alt text](assets/images/Grid_Vs_Randomized_Vs_Bayesian.png)\n",
    " \n",
    "\n",
    " ---\n",
    "\n",
    "While GridSearchCV and RandomizedSearch CV use basics maths (looping, statistics, average, probability distribution), Bayesian Optimization involves advanced maths.                \n",
    "Bayesian Optimization = Use Gaussian Processes to model performance + Acquisition Function to pick best next point based on mean + uncertainty.                  \n",
    "\n",
    "For Bayesian Optimization we should only:                \n",
    "\n",
    "✔ Understand what Bayesian Optimization does               \n",
    "✔ Know when to use it (vs Grid/Random)               \n",
    "✔ Learn how to set search spaces                   \n",
    "✔ Know how acquisition functions behave                \n",
    "✔ Use libraries like sklearn-optuna-hyperopt                   \n",
    "\n",
    "\n",
    "If still interested, Best Resources to understand the maths behind it:                          \n",
    " https://distill.pub/2020/bayesian-optimization/                    \n",
    "\n",
    " ----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe149a",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Let's now use different models with different hyperparameters using GridSearchCV api and try finding best hyperparameters values for these models, all in one single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b45fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading iris flower dataset from sklearn\n",
    "from sklearn import svm, datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4d103cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "47                 4.6               3.2                1.4               0.2   \n",
       "48                 5.3               3.7                1.5               0.2   \n",
       "49                 5.0               3.3                1.4               0.2   \n",
       "50                 7.0               3.2                4.7               1.4   \n",
       "51                 6.4               3.2                4.5               1.5   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "         flower  \n",
       "47       setosa  \n",
       "48       setosa  \n",
       "49       setosa  \n",
       "50   versicolor  \n",
       "51   versicolor  \n",
       "..          ...  \n",
       "145   virginica  \n",
       "146   virginica  \n",
       "147   virginica  \n",
       "148   virginica  \n",
       "149   virginica  \n",
       "\n",
       "[103 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add a new 'flower' column containing the numerical target values (0, 1, 2)\n",
    "df['flower'] = iris.target\n",
    "# Map the numerical targets to actual flower names (e.g., 'setosa', 'versicolor') using a lambda function\n",
    "df['flower'] = df['flower'].apply(lambda x:iris.target_names[x])\n",
    "df[47:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe9957",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-weight:bold\"> 1. Lets try and optimise hyperparameters manually using Train-Test Split method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdb05422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "258f085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', C=30, gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c113f3",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-weight:bold\"> 1. Let's now  use K-Fold Cross Validation to optimise parameters of the model.</span>                    \n",
    "\n",
    "**I am manually supplying different parameters value to the model using sklearn's cross_val_score() method with 5-fold cross validation.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5cf856b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(svm.SVC(kernel='linear', C=10, gamma='auto'), iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "616559bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf', C=10, gamma='auto'), iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db7ec829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf', C=20, gamma='auto'), iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009dce84",
   "metadata": {},
   "source": [
    "**The above steps used by me is manual and not efficient.**            \n",
    "\n",
    "**I am using for loop now to achieve same thing**       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9adda1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': np.float64(0.9800000000000001),\n",
       " 'rbf_10': np.float64(0.9800000000000001),\n",
       " 'rbf_20': np.float64(0.9666666666666668),\n",
       " 'linear_1': np.float64(0.9800000000000001),\n",
       " 'linear_10': np.float64(0.9733333333333334),\n",
       " 'linear_20': np.float64(0.9666666666666666)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "kernels = ['rbf', 'linear']\n",
    "C = [1, 10, 20]\n",
    "\n",
    "avg_scores = {}\n",
    "\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(svm.SVC(kernel=kval, C=cval, gamma='auto'), iris.data, iris.target, cv=5)\n",
    "        avg_scores[kval + '_' + str(cval)] = np.average(cv_scores)\n",
    "        \n",
    "avg_scores       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aca942",
   "metadata": {},
   "source": [
    "**These results tell me that optimal values for Hyperparameters in SVC for this dataset are:**              \n",
    "\n",
    "1. kernel = 'rbf'                   \n",
    "2. C = '1'                  \n",
    "3. gamma = 'auto'                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e05322",
   "metadata": {},
   "source": [
    "**We can use GridSearchCV api which does exact same thing as the above for loop code but in a single line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f123191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00075102, 0.00057797, 0.0006083 , 0.00061078, 0.00068803,\n",
       "        0.00061669]),\n",
       " 'std_fit_time': array([4.17340129e-05, 5.96001433e-05, 2.90348804e-05, 4.99868645e-05,\n",
       "        9.73563694e-05, 5.24392112e-05]),\n",
       " 'mean_score_time': array([0.00052118, 0.00039501, 0.00040722, 0.00041952, 0.00047827,\n",
       "        0.00038557]),\n",
       " 'std_score_time': array([8.61486532e-05, 1.75961311e-05, 1.02303520e-05, 6.06829570e-05,\n",
       "        3.97897680e-05, 1.81451420e-05]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 0.96666667, 1.        , 0.96666667,\n",
       "        1.        ]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.9       , 0.9       ,\n",
       "        0.9       ]),\n",
       " 'split3_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "        0.93333333]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.97333333, 0.96666667,\n",
       "        0.96666667]),\n",
       " 'std_test_score': array([0.01632993, 0.01632993, 0.01632993, 0.03887301, 0.03651484,\n",
       "        0.0421637 ]),\n",
       " 'rank_test_score': array([1, 1, 1, 4, 5, 6], dtype=int32)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1, 10, 20],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b69720",
   "metadata": {},
   "source": [
    "**I know that's not highly readable. So here's the better view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c0d82de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score\n",
       "0        1          rbf         0.980000\n",
       "1        1       linear         0.980000\n",
       "2       10          rbf         0.980000\n",
       "3       10       linear         0.973333\n",
       "4       20          rbf         0.966667\n",
       "5       20       linear         0.966667"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "655db6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52b6cd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9800000000000001)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78fbdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(clf)           #You can check all attritbutes to play around"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624ba99",
   "metadata": {},
   "source": [
    "## We can also use <ins>[RandomisedSearchCV](https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian)</ins> where we don't specify range of values for the parameters.                    \n",
    "\n",
    "**The api tries different combination of parameters.**                                      \n",
    "\n",
    "**This reduces number of iterations and is useful when there are large number of parameters in the model and our computation resources are limited.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "822f427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score\n",
       "0       10       linear         0.973333\n",
       "1        1       linear         0.980000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "            'C': [1, 10, 20],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "}, cv=5, return_train_score=False, n_iter=2)\n",
    "\n",
    "rs.fit(iris.data, iris.target)\n",
    "\n",
    "df = pd.DataFrame(rs.cv_results_)\n",
    "\n",
    "df[['param_C', 'param_kernel', 'mean_test_score']]  # Let's see what parameters values are giving higher accuracy for the model using RandomisedSearchCV api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a45565c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75ff6c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                best_params\n",
       "0                  svm    0.980000  {'C': 1, 'kernel': 'rbf'}\n",
       "1        random_forest    0.953333       {'n_estimators': 10}\n",
       "2  logistic_regression    0.973333                   {'C': 1}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "        clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "        clf.fit(iris.data, iris.target)\n",
    "        scores.append({\n",
    "            'model': model_name,\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "df       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f967472",
   "metadata": {},
   "source": [
    "**Based on the above results of my GridSearchCV on different models i can conclude that SVM model gives me highest accuracy with <e style=color:blue>'C'=1</e> and <e style=color:blue>kernel='rbf'</e>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
