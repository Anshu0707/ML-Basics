{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0fc481",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple; font-weight:bold\">One-Hot Encoding\n",
    "\n",
    "\n",
    "# #<span style=\"color:red; font-weight:bold\">Categorical Variables\n",
    "\n",
    "**When we have one or more categorical variables in the data we need to encode it to numbers because linear regression takes numerical inputs.**    \n",
    "\n",
    "![One Hot Encoding](assets/images/One_Hot_Encoding.png)    \n",
    "\n",
    "---\n",
    "\n",
    "## <span style=\"color:brown; font-weight:bold\">Types of Encoding\n",
    "\n",
    "![Encoding Types](assets/images/Encoding_Types.png)\n",
    "\n",
    "---\n",
    "\n",
    "## <span style=\"color:brown; font-weight:bold\">Types of Categorical Data\n",
    "\n",
    "![Nominal vs Ordinal](assets/images/Nominal_vs_Ordinal.png)\n",
    "\n",
    "---\n",
    "\n",
    "## We will focus on Label and One-Hot Encoding\n",
    "\n",
    "1. <h4 style=\"color:purple\">Label Encoding</h4>\n",
    "   - Assigns a unique integer to each category\n",
    "\n",
    "    ![Label Encoding](assets/images/Label_Encoding.jpg)\n",
    "\n",
    "2. <h4 style=\"color:purple\">One-Hot Encoding</h4>\n",
    "   - Creates a new binary (0 or 1) column for each category, where '1' or 'True' represents hot.\n",
    "\n",
    "    ![One Hot Encoding](assets/images/One_Hot_Encoding.png)\n",
    "\n",
    "---\n",
    "\n",
    "#<span style=\"color:blue\"> Multicollinearity\n",
    "\n",
    "1. **Two or more independent variables** are **highly correlated**, meaning one can be linearly predicted from the others with high accuracy.\n",
    "2. **Introduces inaccuracy** when using One-Hot encoding in Linear Regression.\n",
    "3. To tackle this we intentionally **drop one column randomly** from the One-Hot Encoded columns to reduce (sometimes eliminate) multicollinearity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "befc6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7ba238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./assets/files/homeprices.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a3f5e",
   "metadata": {},
   "source": [
    "**1. Using pandas to create dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f7e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df.town)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e8f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([df,dummies],axis='columns')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8f9a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = merged.drop(['town'], axis='columns')\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0b1c2",
   "metadata": {},
   "source": [
    "**IMPORTANT ! Dummy Variable Trap**\n",
    "\n",
    "When you can derive one variable from other variables, they are known to be multi-colinear. Here if you know values of california and georgia then you can easily infer value of new jersey state, i.e. california=0 and georgia=0. There for these state variables are called to be multi-colinear. In this situation linear regression won't work as expected. Hence you need to drop one column.\n",
    "\n",
    "**NOTE: sklearn library takes care of dummy variable trap hence even if you don't drop one of the state columns it is going to work, however we should make a habit of taking care of dummy variable trap ourselves just in case library that you are using is not handling this for you**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b1c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(['west windsor'], axis='columns')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.drop('price', axis='columns')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2d3e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3e4f5g6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4f5g6h7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5g6h7i8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X) # 2600 sqr ft home in new jersey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "g6h7i8j9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "h7i8j9k0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[3400,0,0]]) # 3400 sqr ft home in west windsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "i8j9k0l1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[2800,0,1]]) # 2800 sqr ft home in robbinsville"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9k0l1m2",
   "metadata": {},
   "source": [
    "**2. Using sklearn OneHotEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "k0l1m2n3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "l1m2n3o4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfle = df\n",
    "dfle.town = le.fit_transform(dfle.town)\n",
    "dfle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "m2n3o4p5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfle[['town','area']].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "n3o4p5q6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfle.price.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "o4p5q6r7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('town', OneHotEncoder(), [0])], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "p5q6r7s8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "q6r7s8t9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "r7s8t9u0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "s8t9u0v1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0,1,3400]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "t9u0v1w2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[1,0,2800]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
